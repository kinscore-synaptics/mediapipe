# MediaPipe graph to detect/predict pose landmarks. (CPU input, and inference is
# executed on CPU.) This graph tries to skip pose detection as much as possible
# by using previously detected/predicted landmarks for new images.
#
# It is required that "pose_detection.tflite" is available at
# "mediapipe/modules/pose_detection/pose_detection.tflite"
# path during execution.
#
# It is required that "pose_landmark_full_body.tflite" or
# "pose_landmark_upper_body.tflite" is available at
# "mediapipe/modules/pose_landmark/pose_landmark_full_body.tflite"
# or
# "mediapipe/modules/pose_landmark/pose_landmark_upper_body.tflite"
# path respectively during execution, depending on the specification in the
# UPPER_BODY_ONLY input side packet.
#
# EXAMPLE:
#   node {
#     calculator: "PoseLandmarkCpu"
#     input_side_packet: "UPPER_BODY_ONLY:upper_body_only"
#     input_side_packet: "SMOOTH_LANDMARKS:smooth_landmarks"
#     output_stream: "LANDMARKS:pose_landmarks"
#   }

type: "PintoPoseLandmarkCpu"

input_stream: "INPUT_DETECTIONS:input_detections"

input_stream: "INPUT_LANDMARKS:input_landmarks"

# Pose landmarks within the given ROI. (NormalizedLandmarkList)
# We have 33 landmarks (see pose_landmark_full_body_topology.svg) with the
# first 25 fall on the upper body (see pose_landmark_upper_body_topology.svg),
# and there are other auxiliary key points.
# 0 - nose
# 1 - left eye (inner)
# 2 - left eye
# 3 - left eye (outer)
# 4 - right eye (inner)
# 5 - right eye
# 6 - right eye (outer)
# 7 - left ear
# 8 - right ear
# 9 - mouth (left)
# 10 - mouth (right)
# 11 - left shoulder
# 12 - right shoulder
# 13 - left elbow
# 14 - right elbow
# 15 - left wrist
# 16 - right wrist
# 17 - left pinky
# 18 - right pinky
# 19 - left index
# 20 - right index
# 21 - left thumb
# 22 - right thumb
# 23 - left hip
# 24 - right hip
# 25 - left knee
# 26 - right knee
# 27 - left ankle
# 28 - right ankle
# 29 - left heel
# 30 - right heel
# 31 - left foot index
# 32 - right foot index
#

# Extra outputs (for debugging, for instance).
# Detected poses. (Detection)
output_stream: "unfiltered_detections"

output_stream: "LANDMARKS_FLOATS:landmark_floats"

output_stream: "raw_landmarks"

# Generates a single side packet containing a vector of SSD anchors based on
# the specification in the options.
node {
  calculator: "SsdAnchorsCalculator"
  output_side_packet: "anchors"
  options: {
    [mediapipe.SsdAnchorsCalculatorOptions.ext] {
      num_layers: 4
      min_scale: 0.1484375
      max_scale: 0.75
      input_size_height: 128
      input_size_width: 128
      anchor_offset_x: 0.5
      anchor_offset_y: 0.5
      strides: 8
      strides: 16
      strides: 16
      strides: 16
      aspect_ratios: 1.0
      fixed_anchor_size: true
    }
  }
}

node {
  calculator: "PoseDetectFloatsCalculator"
  input_stream: "FLOATS:input_detections"
  output_stream: "TENSORS:input_detection_tensors"
}

# Decodes the detection tensors generated by the TensorFlow Lite model, based on
# the SSD anchors and the specification in the options, into a vector of
# detections. Each detection describes a detected object.
node {
  calculator: "TensorsToDetectionsCalculator"
  input_stream: "TENSORS:input_detection_tensors"
  input_side_packet: "ANCHORS:anchors"
  output_stream: "DETECTIONS:unfiltered_detections"
  options: {
    [mediapipe.TensorsToDetectionsCalculatorOptions.ext] {
      num_classes: 1
      num_boxes: 896
      num_coords: 12
      box_coord_offset: 0
      keypoint_coord_offset: 4
      num_keypoints: 4
      num_values_per_keypoint: 2
      sigmoid_score: true
      score_clipping_thresh: 100.0
      reverse_output_order: true
      x_scale: 128.0
      y_scale: 128.0
      h_scale: 128.0
      w_scale: 128.0
      min_score_thresh: 0.5
    }
  }
}

# Performs non-max suppression to remove excessive detections.
node {
  calculator: "NonMaxSuppressionCalculator"
  input_stream: "unfiltered_detections"
  output_stream: "filtered_detections"
  options: {
    [mediapipe.NonMaxSuppressionCalculatorOptions.ext] {
      min_suppression_threshold: 0.3
      overlap_type: INTERSECTION_OVER_UNION
      algorithm: WEIGHTED
    }
  }
}

node {
  calculator: "PoseLandmarkFloatsCalculator"
  input_stream: "FLOATS:input_landmarks"
  output_stream: "TENSORS:input_landmark_tensors"
}

node {
  calculator: "TensorsToLandmarksCalculator"
  input_stream: "TENSORS:input_landmark_tensors"
  output_stream: "NORM_LANDMARKS:raw_landmarks"
  options: {
    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {
      num_landmarks: 35
      input_image_width: 256
      input_image_height: 256
      visibility_activation: SIGMOID
      presence_activation: SIGMOID
    }
  }
}

node {
  calculator: "TensorsToFloatsCalculator"
  input_stream: "TENSORS:input_landmark_tensors"
  output_stream: "FLOATS:landmark_floats"
  options: {
    [mediapipe.TensorsToFloatsCalculatorOptions.ext] {
      index: 0
    }
  }
}

